
import os
import streamlit as st
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores import FAISS
from langchain.chat_models import ChatOpenAI
from langchain.document_loaders import PyPDFLoader, DataFrameLoader
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain.tools.retriever import create_retriever_tool
from langchain.prompts import ChatPromptTemplate
from langchain.agents import create_tool_calling_agent, AgentExecutor
import pandas as pd

# .env íŒŒì¼ ë¡œë“œ
os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"
os.environ['OPENAI_API_KEY'] = st.secrets["OPENAI_API_KEY"]

# í´ë” ê²½ë¡œ ì„¤ì •
folder_path = "./data"  # ë¶„ì„í•  íŒŒì¼ì´ ì €ì¥ëœ í´ë” ê²½ë¡œ
text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)

# PDF ë¬¸ì„œ ë¡œë“œ í•¨ìˆ˜
def load_pdf_with_metadata(file_path):
    loader = PyPDFLoader(file_path)
    documents = loader.load_and_split(text_splitter)
    for doc in documents:
        doc.metadata["source"] = os.path.basename(file_path)
        doc.metadata["page"] = doc.metadata.get("page", "Unknown")
    return documents

# ì—‘ì…€ ë¬¸ì„œ ë¡œë“œ í•¨ìˆ˜
def load_excel_with_metadata(file_path):
    documents = []
    xls = pd.ExcelFile(file_path)
    for sheet_name in xls.sheet_names:
        df = pd.read_excel(file_path, sheet_name=sheet_name)
        loader = DataFrameLoader(df, page_content_column=df.columns[0])
        sheet_docs = loader.load_and_split(text_splitter)
        for doc in sheet_docs:
            doc.metadata["source"] = os.path.basename(file_path)
            doc.metadata["sheet_name"] = sheet_name
            doc.metadata["cell_range"] = f"A1:{df.columns[-1]}{len(df)}"  # ì¶”ê°€ ì…€ ë²”ìœ„ ì •ë³´
        documents.extend(sheet_docs)
    return documents


# CSV ë¬¸ì„œ ë¡œë“œ í•¨ìˆ˜
def load_csv_with_metadata(file_path):
    documents = []
    df = pd.read_csv(file_path)
    loader = DataFrameLoader(df, page_content_column=df.columns[0])
    csv_docs = loader.load_and_split(text_splitter)
    for doc in csv_docs:
        doc.metadata["source"] = os.path.basename(file_path)
        doc.metadata["cell_range"] = f"A1:{df.columns[-1]}{len(df)}"  # ì¶”ê°€ ì…€ ë²”ìœ„ ì •ë³´
    documents.extend(csv_docs)
    return documents

# í´ë” ë‚´ ëª¨ë“  ë¬¸ì„œë¥¼ ë¡œë“œ

def load_documents_from_folder(folder_path):
    documents = []
    for file_name in os.listdir(folder_path):
        file_path = os.path.join(folder_path, file_name)
        if file_name.endswith(".pdf"):
            documents.extend(load_pdf_with_metadata(file_path))
        elif file_name.endswith(".xlsx") or file_name.endswith(".xls"):
            documents.extend(load_excel_with_metadata(file_path))
        elif file_name.endswith(".csv"):
            documents.extend(load_csv_with_metadata(file_path))
    return documents



# ì—ì´ì „íŠ¸ì™€ ëŒ€í™”í•˜ëŠ” í•¨ìˆ˜
def chat_with_agent(user_input, agent_executor):
    result = agent_executor({"input": user_input})
    response = result['output']  # ëª…ì‹œì ìœ¼ë¡œ ì¶œë ¥ í‚¤ë¥¼ ì²˜ë¦¬
    return response

# ì„¸ì…˜ ê¸°ë¡ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜
def get_session_history(session_ids):
    if session_ids not in st.session_state.session_history:
        st.session_state.session_history[session_ids] = ChatMessageHistory()
    return st.session_state.session_history[session_ids]

# ëŒ€í™” ë‚´ìš© ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜
def print_messages():
    for msg in st.session_state["messages"]:
        st.chat_message(msg['role']).write(msg['content'])


# ëª¨ë“  ë¬¸ì„œ ë¡œë“œ
all_docs = load_documents_from_folder(folder_path)


# FAISS ì¸ë±ìŠ¤ ì„¤ì • ë° ìƒì„±
vector = FAISS.from_documents(all_docs, OpenAIEmbeddings())
retriever = vector.as_retriever()

# ë„êµ¬ ì •ì˜
retriever_tool = create_retriever_tool(
    retriever,
    name="retriever_tool",
    description="Use this tool to search information from the pdf document"
)

# Streamlit ë©”ì¸ ì½”ë“œ
def main():
    # í˜ì´ì§€ ì„¤ì •
    st.set_page_config(page_title="í•˜ë„ê¸‰ ê´€ë ¨ ìƒë‹´ ì „ë¬¸ê°€ DoguBee", layout="wide", page_icon="ğŸ")

    st.image('DoguBee.png', width=450)
    st.markdown('---')
    st.title("ì•ˆë…•í•˜ì„¸ìš”! í•˜ë„ê¸‰ ê´€ë ¨ ìƒë‹´ ì „ë¬¸ê°€ 'DoguBee' ì…ë‹ˆë‹¤")  # ì‹œì‘ íƒ€ì´í‹€

    # ì„¸ì…˜ ì´ˆê¸°í™”
    if "messages" not in st.session_state:
        st.session_state["messages"] = []

    if "session_history" not in st.session_state:
        st.session_state["session_history"] = {}


# return retriever_tool
    tools = [retriever_tool]

    # LLM ì„¤ì •
    llm = ChatOpenAI(model_name="gpt-4o", temperature=0)

    # Prompt ì •ì˜
    prompt = ChatPromptTemplate.from_messages(
        [
            (
                "system",
                    "You are an expert in subcontracting law. "
                    "Use sophisticated and credible language to maintain authority. "
                    "When providing examples or case-related answers, organize them clearly by separating each case for better readability."
                    "Always end your responses with a phrase encouraging additional questions, such as 'Feel free to ask if you have further questions.'"
                    "Do not answer questions unrelated to subcontracting law. Instead, respond with a message like: 'This question is not related to subcontracting law. Please ask only about matters related to subcontracting law."
                    
                    "Please always reply in Korean and kindly."

            ),
            ("placeholder", "{chat_history}"),
            ("human", "{input}"),
            ("placeholder", "{agent_scratchpad}"),
        ]
    )

    # ì—ì´ì „íŠ¸ ìƒì„± (initialize_agent ëŒ€ì‹  create_tool_calling_agent ì‚¬ìš©)
    agent = create_tool_calling_agent(llm, tools, prompt)

    # AgentExecutor ì •ì˜
    agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)

    # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
    user_input = st.chat_input('ì§ˆë¬¸ì´ ë¬´ì—‡ì¸ê°€ìš”?')

    if user_input:
        session_id = "default_session"
        session_history = get_session_history(session_id)

        if session_history.messages:
            previous_messages = [{"role": msg['role'], "content": msg['content']} for msg in session_history.messages]
            response = chat_with_agent(user_input + "\n\nPrevious Messages: " + str(previous_messages), agent_executor)
        else:
            response = chat_with_agent(user_input, agent_executor)

        # ë©”ì‹œì§€ë¥¼ ì„¸ì…˜ì— ì¶”ê°€
        st.session_state["messages"].append({"role": "user", "content": user_input})
        st.session_state["messages"].append({"role": "assistant", "content": response})

        # ì„¸ì…˜ ê¸°ë¡ì— ë©”ì‹œì§€ë¥¼ ì¶”ê°€
        session_history.add_message({"role": "user", "content": user_input})
        session_history.add_message({"role": "assistant", "content": response})

        # ëŒ€í™” ë‚´ìš© ì¶œë ¥
        print_messages()



if __name__ == "__main__":
    main()
